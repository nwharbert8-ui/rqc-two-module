{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MS1: Supplementary Analyses \u2014 Permutation, Bootstrap, Threshold Sensitivity\n",
        "\n",
        "Run AFTER MS1_RQC_COMPLETE.ipynb in the same session. Generates Figures S1\u2013S3 and Tables S5\u2013S8.\n",
        "\n",
        "**Author:** Drake H. Harbert \u2014 Inner Architecture LLC\n",
        "\n",
        "**Environment:** Google Colab, \u226412 GB RAM, Google Drive mounted\n",
        "\n[![Open In Colab](https://colab.research.google.com/github/innerarchitecturellc/rqc-two-module/blob/main/notebooks/MS1_RQC_SUPPLEMENT.ipynb)](https://colab.research.google.com/github/innerarchitecturellc/rqc-two-module/blob/main/notebooks/MS1_RQC_SUPPLEMENT.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL S1 \u2014 Permutation null model for Jaccard indices\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=\" * 70)\nprint(\"CELL S1 \u2014 PERMUTATION NULL MODEL (10,000 iterations)\")\nprint(\"=\" * 70)\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport time, gc\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nnp.random.seed(42)\n\n# Precompute standardized expression matrix for fast Pearson via dot product\n# Pearson(x, y) = dot(z_x, z_y) / (n - 1) where z = (x - mean) / std\nprint(\"  Precomputing standardized expression matrix...\")\nexpr_mat = expr_v[other_genes].values.T  # (genes \u00d7 samples)\nexpr_means = expr_mat.mean(axis=1, keepdims=True)\nexpr_stds = expr_mat.std(axis=1, ddof=1, keepdims=True)\nexpr_stds[expr_stds == 0] = 1.0  # avoid division by zero\nZ = (expr_mat - expr_means) / expr_stds  # (genes \u00d7 samples)\nn_samp = Z.shape[1]\ngene_index = {g: i for i, g in enumerate(other_genes)}\n\nprint(f\"  Z matrix: {Z.shape[0]} genes \u00d7 {Z.shape[1]} samples\")\nprint(f\"  RAM for Z: ~{Z.nbytes / 1e9:.2f} GB\")\n\ndef fast_jaccard_for_gene_pair(idx_a, idx_b, Z, n_top, n_samp):\n    \"\"\"Compute Jaccard between top-5% networks of two genes using vectorized Pearson.\"\"\"\n    # Correlation of gene A with all others\n    corr_a = Z @ Z[idx_a] / (n_samp - 1)\n    corr_b = Z @ Z[idx_b] / (n_samp - 1)\n\n    # Zero out self-correlations\n    corr_a[idx_a] = -999\n    corr_b[idx_b] = -999\n    # Zero out cross-correlation (gene B in A's ranking and vice versa)\n    corr_a[idx_b] = -999\n    corr_b[idx_a] = -999\n\n    # Top n_top by descending correlation\n    top_a = set(np.argpartition(corr_a, -n_top)[-n_top:])\n    top_b = set(np.argpartition(corr_b, -n_top)[-n_top:])\n\n    inter = len(top_a & top_b)\n    union = len(top_a | top_b)\n    return inter / union if union > 0 else 0.0\n\nN_PERM = 10000\nnull_jaccards = np.zeros(N_PERM)\n\nt0 = time.time()\nprint(f\"\\n  Running {N_PERM} permutations...\")\nfor i in range(N_PERM):\n    # Pick 2 random genes (without replacement)\n    pair = np.random.choice(len(other_genes), size=2, replace=False)\n    null_jaccards[i] = fast_jaccard_for_gene_pair(pair[0], pair[1], Z, n_top, n_samp)\n    if (i + 1) % 2000 == 0:\n        elapsed = time.time() - t0\n        rate = (i + 1) / elapsed\n        eta = (N_PERM - i - 1) / rate\n        print(f\"    {i+1}/{N_PERM} done ({elapsed:.0f}s elapsed, ~{eta:.0f}s remaining)\")\n\nelapsed = time.time() - t0\nprint(f\"  Completed {N_PERM} permutations in {elapsed:.1f}s\")\n\n# Null distribution statistics\nnull_mean = np.mean(null_jaccards)\nnull_std = np.std(null_jaccards)\nnull_median = np.median(null_jaccards)\nnull_p95 = np.percentile(null_jaccards, 95)\nnull_p99 = np.percentile(null_jaccards, 99)\nnull_max = np.max(null_jaccards)\n\nprint(f\"\\n  NULL DISTRIBUTION (n={N_PERM}):\")\nprint(f\"    Mean:   {null_mean:.4f}\")\nprint(f\"    Std:    {null_std:.4f}\")\nprint(f\"    Median: {null_median:.4f}\")\nprint(f\"    95th:   {null_p95:.4f}\")\nprint(f\"    99th:   {null_p99:.4f}\")\nprint(f\"    Max:    {null_max:.4f}\")\n\n# Observed values & empirical p-values / z-scores\nprint(f\"\\n  OBSERVED vs NULL:\")\nfor g1, g2 in pairs:\n    obs_j = pairwise[(g1, g2)][\"jaccard\"]\n    z_score = (obs_j - null_mean) / null_std\n    emp_p = np.sum(null_jaccards >= obs_j) / N_PERM\n    fold_above = obs_j / null_mean if null_mean > 0 else float('inf')\n    print(f\"    {g1}-{g2}: J={obs_j:.4f}, z={z_score:.1f}, \"\n          f\"empirical p={emp_p:.4f} ({emp_p * N_PERM:.0f}/{N_PERM}), \"\n          f\"fold-above-mean={fold_above:.1f}\u00d7\")\n\n# \u2500\u2500 Figure S1: Null distribution with observed values \u2500\u2500\nfig_s1, ax = plt.subplots(figsize=(8, 5))\nax.hist(null_jaccards, bins=80, color='#B0C4DE', edgecolor='white',\n        linewidth=0.3, density=True, alpha=0.85, label='Null distribution')\n\n# Observed lines\ncolors = {'PELO-LTN1': '#E74C3C', 'PELO-NEMF': '#F39C12', 'LTN1-NEMF': '#2E86C1'}\nfor g1, g2 in pairs:\n    obs_j = pairwise[(g1, g2)][\"jaccard\"]\n    label = f\"{g1}\u2013{g2}\"\n    ax.axvline(obs_j, color=colors[f\"{g1}-{g2}\"], linewidth=2.5,\n               linestyle='--', label=f'{label} (J={obs_j:.3f})')\n\nax.set_xlabel('Jaccard Index', fontsize=12)\nax.set_ylabel('Density', fontsize=12)\nax.set_title('Permutation Null Distribution of Jaccard Indices\\n'\n             f'(n={N_PERM:,} random gene pairs, top 5% networks)',\n             fontsize=13, fontweight='bold')\nax.legend(fontsize=10, loc='upper right')\nax.set_xlim(-0.005, max(0.12, null_max * 1.2))\n\n# Inset text box with statistics\ntextstr = (f'Null: \u03bc={null_mean:.4f}, \u03c3={null_std:.4f}\\n'\n           f'95th pctl: {null_p95:.4f}\\n'\n           f'99th pctl: {null_p99:.4f}')\nprops = dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.9, edgecolor='gray')\nax.text(0.62, 0.75, textstr, transform=ax.transAxes, fontsize=9,\n        verticalalignment='top', bbox=props)\n\nplt.tight_layout()\nfig_s1.savefig(f'{OUT}/figures/FigureS1_permutation_null.pdf')\nfig_s1.savefig(f'{OUT}/figures/FigureS1_permutation_null.png')\nplt.close(fig_s1)\nprint(\"\\n  Figure S1 saved.\")\n\n# Save null distribution\nnull_df = pd.DataFrame({'jaccard': null_jaccards})\nnull_df.to_csv(f'{OUT}/supplementary/TableS5_null_distribution.csv', index=False)\nprint(\"  Table S5 (null distribution) saved.\")\n\n# Clean up Z matrix to free RAM\ndel Z, expr_mat, expr_means, expr_stds\ngc.collect()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL S2 \u2014 Specific region pairs driving sub-0.80 correlations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"CELL S2 \u2014 CROSS-REGION PAIR DECOMPOSITION\")\nprint(\"=\" * 70)\n\n# Extract all 10 pairwise \u03c1 values per target from cross_region_rho matrices\nprint(f\"\\n  Regions: {region_abbrs}\")\nprint(f\"  Region pairs: {len(region_abbrs) * (len(region_abbrs) - 1) // 2}\")\n\n# Also get sample sizes per region for context\nregion_n = {}\nfor abbr in region_abbrs:\n    region_n[abbr] = region_data[abbr][\"n_samples\"]\n    print(f\"  {abbr}: n={region_n[abbr]}\")\n\nall_pairs_data = []\nfor target in TARGETS:\n    mat = cross_region_rho[target]\n    print(f\"\\n  {target}:\")\n    print(f\"  {'Pair':<12} {'\u03c1':>8}  {'n\u2081':>5}  {'n\u2082':>5}  {'> 0.80':>7}\")\n    print(f\"  {'\u2500'*45}\")\n    for i, r1 in enumerate(region_abbrs):\n        for j, r2 in enumerate(region_abbrs):\n            if i < j:\n                rho = mat.loc[r1, r2]\n                n1 = region_n[r1]\n                n2 = region_n[r2]\n                flag = \"  \u2713\" if rho > 0.80 else \"  *** LOW\"\n                print(f\"  {r1}\u2013{r2:<7} {rho:8.4f}  {n1:5d}  {n2:5d}  {flag}\")\n                all_pairs_data.append({\n                    'Gene': target,\n                    'Region 1': r1,\n                    'Region 2': r2,\n                    'Spearman \u03c1': round(rho, 4),\n                    'n (Region 1)': n1,\n                    'n (Region 2)': n2,\n                    'Above 0.80': 'Yes' if rho > 0.80 else 'No'\n                })\n\n# Save as Table S6\npairs_df = pd.DataFrame(all_pairs_data)\npairs_df.to_csv(f'{OUT}/supplementary/TableS6_cross_region_all_pairs.csv', index=False)\nprint(f\"\\n  Table S6 saved ({len(all_pairs_data)} region-pair entries).\")\n\n# Summary: which pairs are sub-0.80?\nprint(f\"\\n  SUB-0.80 PAIRS:\")\nsub80 = pairs_df[pairs_df['Above 0.80'] == 'No']\nif len(sub80) == 0:\n    print(\"    None\")\nelse:\n    for _, row in sub80.iterrows():\n        print(f\"    {row['Gene']}: {row['Region 1']}\u2013{row['Region 2']} \"\n              f\"\u03c1={row['Spearman \u03c1']:.4f} \"\n              f\"(n={row['n (Region 1)']}, n={row['n (Region 2)']})\")\n\n# PELO vs LTN1/NEMF comparison: count how many pairs > 0.80 for each\nprint(f\"\\n  PAIRS ABOVE 0.80 THRESHOLD:\")\nfor target in TARGETS:\n    t_df = pairs_df[pairs_df['Gene'] == target]\n    above = t_df['Above 0.80'].value_counts().get('Yes', 0)\n    total = len(t_df)\n    print(f\"    {target}: {above}/{total} pairs above 0.80 \"\n          f\"({above/total*100:.0f}%)\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL S3 \u2014 Bootstrap confidence intervals on Jaccard indices\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"CELL S3 \u2014 BOOTSTRAP CONFIDENCE INTERVALS (1,000 resamples)\")\nprint(\"=\" * 70)\n\nnp.random.seed(123)\nN_BOOT = 1000\n\n# Precompute full expression array for fast resampling\nexpr_array = expr_v[other_genes].values  # (samples \u00d7 genes)\ntarget_arrays = {t: expr_v[t].values for t in TARGETS}\nn_samples_boot = expr_array.shape[0]\nn_genes_boot = expr_array.shape[1]\n\nprint(f\"  Samples: {n_samples_boot}, Genes: {n_genes_boot}, Top 5%: {n_top}\")\n\nboot_jaccards = {p: np.zeros(N_BOOT) for p in pairs}\nboot_spearman = {p: np.zeros(N_BOOT) for p in pairs}\n\nt0 = time.time()\nfor b in range(N_BOOT):\n    # Resample sample indices with replacement\n    idx = np.random.choice(n_samples_boot, size=n_samples_boot, replace=True)\n\n    # Resampled expression\n    X_boot = expr_array[idx]  # (n_samples \u00d7 n_genes)\n\n    # Compute correlations for each target via vectorized Pearson\n    boot_top5 = {}\n    boot_rankings = {}\n    for target in TARGETS:\n        t_boot = target_arrays[target][idx]\n\n        # Vectorized Pearson: corr(t, each column of X)\n        t_mean = t_boot.mean()\n        t_std = t_boot.std(ddof=1)\n        if t_std == 0:\n            continue\n        t_z = (t_boot - t_mean) / t_std\n\n        x_means = X_boot.mean(axis=0)\n        x_stds = X_boot.std(axis=0, ddof=1)\n        x_stds[x_stds == 0] = 1.0\n        X_z = (X_boot - x_means) / x_stds  # (samples \u00d7 genes)\n\n        corrs = (t_z @ X_z) / (n_samples_boot - 1)  # (genes,)\n\n        # Get top n_top indices\n        top_idx = set(np.argpartition(corrs, -n_top)[-n_top:])\n        boot_top5[target] = top_idx\n        boot_rankings[target] = corrs\n\n    # Compute pairwise Jaccards and Spearman\n    for g1, g2 in pairs:\n        if g1 in boot_top5 and g2 in boot_top5:\n            s1, s2 = boot_top5[g1], boot_top5[g2]\n            inter = len(s1 & s2)\n            union = len(s1 | s2)\n            boot_jaccards[(g1, g2)][b] = inter / union if union > 0 else 0.0\n\n            rho, _ = stats.spearmanr(boot_rankings[g1], boot_rankings[g2])\n            boot_spearman[(g1, g2)][b] = rho\n\n    if (b + 1) % 200 == 0:\n        elapsed = time.time() - t0\n        rate = (b + 1) / elapsed\n        eta = (N_BOOT - b - 1) / rate\n        print(f\"    {b+1}/{N_BOOT} done ({elapsed:.0f}s, ~{eta:.0f}s remaining)\")\n\nelapsed = time.time() - t0\nprint(f\"  Completed {N_BOOT} bootstrap iterations in {elapsed:.1f}s\")\n\n# Report CIs\nprint(f\"\\n  BOOTSTRAP 95% CONFIDENCE INTERVALS:\")\nprint(f\"  {'Pair':<14} {'Observed J':>11} {'95% CI (J)':>22} \"\n      f\"{'Observed \u03c1':>11} {'95% CI (\u03c1)':>22}\")\nprint(f\"  {'\u2500'*82}\")\n\nci_data = []\nfor g1, g2 in pairs:\n    obs_j = pairwise[(g1, g2)][\"jaccard\"]\n    obs_rho = pairwise[(g1, g2)][\"spearman\"]\n    j_lo, j_hi = np.percentile(boot_jaccards[(g1, g2)], [2.5, 97.5])\n    r_lo, r_hi = np.percentile(boot_spearman[(g1, g2)], [2.5, 97.5])\n    print(f\"  {g1}\u2013{g2:<8} {obs_j:11.4f} [{j_lo:.4f}, {j_hi:.4f}]\"\n          f\" {obs_rho:11.4f} [{r_lo:.4f}, {r_hi:.4f}]\")\n    ci_data.append({\n        'Pair': f'{g1}\u2013{g2}', 'Observed Jaccard': obs_j,\n        'Jaccard 2.5%': round(j_lo, 4), 'Jaccard 97.5%': round(j_hi, 4),\n        'Observed Spearman': obs_rho,\n        'Spearman 2.5%': round(r_lo, 4), 'Spearman 97.5%': round(r_hi, 4),\n    })\n\n# Check non-overlap of CIs\npelo_ltn1_hi = np.percentile(boot_jaccards[(\"PELO\",\"LTN1\")], 97.5)\npelo_nemf_hi = np.percentile(boot_jaccards[(\"PELO\",\"NEMF\")], 97.5)\nltn1_nemf_lo = np.percentile(boot_jaccards[(\"LTN1\",\"NEMF\")], 2.5)\n\nprint(f\"\\n  CI NON-OVERLAP TEST (two-module separation):\")\nprint(f\"    Max upper CI of PELO pairs: {max(pelo_ltn1_hi, pelo_nemf_hi):.4f}\")\nprint(f\"    Lower CI of LTN1\u2013NEMF:      {ltn1_nemf_lo:.4f}\")\nif ltn1_nemf_lo > max(pelo_ltn1_hi, pelo_nemf_hi):\n    print(f\"    \u2192 CIs DO NOT OVERLAP: Two-module separation is robust.\")\nelse:\n    gap = ltn1_nemf_lo - max(pelo_ltn1_hi, pelo_nemf_hi)\n    print(f\"    \u2192 Gap: {gap:.4f} (overlap exists if negative)\")\n\n# \u2500\u2500 Figure S2: Bootstrap distributions \u2500\u2500\nfig_s2, axes = plt.subplots(1, 3, figsize=(14, 4.5))\ncolors_list = ['#E74C3C', '#F39C12', '#2E86C1']\nlabels_list = ['PELO\u2013LTN1', 'PELO\u2013NEMF', 'LTN1\u2013NEMF']\n\nfor idx, (g1, g2) in enumerate(pairs):\n    ax = axes[idx]\n    data = boot_jaccards[(g1, g2)]\n    obs_j = pairwise[(g1, g2)][\"jaccard\"]\n    lo, hi = np.percentile(data, [2.5, 97.5])\n\n    ax.hist(data, bins=50, color=colors_list[idx], alpha=0.7,\n            edgecolor='white', linewidth=0.3, density=True)\n    ax.axvline(obs_j, color='black', linewidth=2, linestyle='-',\n               label=f'Observed: {obs_j:.3f}')\n    ax.axvline(lo, color='gray', linewidth=1.5, linestyle='--',\n               label=f'95% CI: [{lo:.3f}, {hi:.3f}]')\n    ax.axvline(hi, color='gray', linewidth=1.5, linestyle='--')\n\n    # Shade CI region\n    ax.axvspan(lo, hi, alpha=0.15, color='gray')\n\n    ax.set_xlabel('Jaccard Index', fontsize=11)\n    ax.set_ylabel('Density', fontsize=11)\n    ax.set_title(f'{labels_list[idx]}', fontsize=12, fontweight='bold')\n    ax.legend(fontsize=8, loc='upper left')\n\nplt.suptitle(f'Bootstrap Distributions of Jaccard Indices (n={N_BOOT:,} resamples)',\n             fontsize=13, fontweight='bold', y=1.02)\nplt.tight_layout()\nfig_s2.savefig(f'{OUT}/figures/FigureS2_bootstrap_jaccard.pdf')\nfig_s2.savefig(f'{OUT}/figures/FigureS2_bootstrap_jaccard.png')\nplt.close(fig_s2)\nprint(\"\\n  Figure S2 saved.\")\n\n# Save bootstrap CIs\nci_df = pd.DataFrame(ci_data)\nci_df.to_csv(f'{OUT}/supplementary/TableS7_bootstrap_CIs.csv', index=False)\nprint(\"  Table S7 saved.\")\n\ndel X_boot, boot_rankings, boot_top5\ngc.collect()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL S4 \u2014 Threshold sensitivity analysis (1%, 3%, 5%, 7%, 10%)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"CELL S4 \u2014 THRESHOLD SENSITIVITY ANALYSIS\")\nprint(\"=\" * 70)\n\nTHRESHOLDS = [0.01, 0.02, 0.03, 0.05, 0.07, 0.10, 0.15, 0.20]\n\n# Use the pre-computed genome-wide correlations from main pipeline\nsensitivity_rows = []\npartition_ratios = []\n\nprint(f\"\\n  {'Threshold':>10} {'PELO-LTN1':>11} {'PELO-NEMF':>11} {'LTN1-NEMF':>11} \"\n      f\"{'Ratio':>8} {'Separation':>12}\")\nprint(f\"  {'\u2500'*67}\")\n\nfor pct in THRESHOLDS:\n    n_t = int(n_other * pct)\n    if n_t < 10:\n        print(f\"  {pct*100:9.0f}%  (skipped: n_top={n_t} too small)\")\n        continue\n\n    # Get top sets at this threshold\n    top_sets = {}\n    for target in TARGETS:\n        top_sets[target] = set(correlations[target].head(n_t).index)\n\n    # Pairwise Jaccards\n    jaccards = {}\n    for g1, g2 in pairs:\n        s1, s2 = top_sets[g1], top_sets[g2]\n        inter = len(s1 & s2)\n        union = len(s1 | s2)\n        jaccards[(g1, g2)] = inter / union if union > 0 else 0.0\n\n    # Partition ratio = LTN1-NEMF Jaccard / max(PELO-LTN1, PELO-NEMF)\n    pelo_max = max(jaccards[(\"PELO\",\"LTN1\")], jaccards[(\"PELO\",\"NEMF\")])\n    ratio = jaccards[(\"LTN1\",\"NEMF\")] / pelo_max if pelo_max > 0 else float('inf')\n\n    # Is the partition maintained? (ratio > 1.5 = clear separation)\n    sep = \"STRONG\" if ratio > 2.0 else (\"MODERATE\" if ratio > 1.5 else \"WEAK\")\n\n    print(f\"  {pct*100:9.0f}% {jaccards[('PELO','LTN1')]:11.4f} \"\n          f\"{jaccards[('PELO','NEMF')]:11.4f} {jaccards[('LTN1','NEMF')]:11.4f} \"\n          f\"{ratio:8.2f}\u00d7 {sep:>12}\")\n\n    sensitivity_rows.append({\n        'Threshold (%)': pct * 100,\n        'n_top': n_t,\n        'PELO-LTN1 Jaccard': round(jaccards[(\"PELO\",\"LTN1\")], 4),\n        'PELO-NEMF Jaccard': round(jaccards[(\"PELO\",\"NEMF\")], 4),\n        'LTN1-NEMF Jaccard': round(jaccards[(\"LTN1\",\"NEMF\")], 4),\n        'Partition ratio': round(ratio, 2),\n        'Separation': sep,\n    })\n    partition_ratios.append({\n        'pct': pct * 100,\n        'ratio': ratio,\n        'j_pl': jaccards[(\"PELO\",\"LTN1\")],\n        'j_pn': jaccards[(\"PELO\",\"NEMF\")],\n        'j_ln': jaccards[(\"LTN1\",\"NEMF\")],\n    })\n\n# Also compute threshold-independent Spearman (already have this)\nprint(f\"\\n  THRESHOLD-INDEPENDENT SPEARMAN RANK CORRELATIONS (full genome):\")\nfor g1, g2 in pairs:\n    print(f\"    {g1}\u2013{g2}: \u03c1 = {pairwise[(g1,g2)]['spearman']:.4f}\")\n\n# \u2500\u2500 Figure S3: Threshold sensitivity plot (dual panel) \u2500\u2500\nfig_s3, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5))\n\npcts = [r['pct'] for r in partition_ratios]\nj_pl = [r['j_pl'] for r in partition_ratios]\nj_pn = [r['j_pn'] for r in partition_ratios]\nj_ln = [r['j_ln'] for r in partition_ratios]\nratios = [r['ratio'] for r in partition_ratios]\n\n# Panel A: Jaccard indices across thresholds\nax1.plot(pcts, j_pl, 'o-', color='#E74C3C', linewidth=2, markersize=7,\n         label='PELO\u2013LTN1', zorder=3)\nax1.plot(pcts, j_pn, 's-', color='#F39C12', linewidth=2, markersize=7,\n         label='PELO\u2013NEMF', zorder=3)\nax1.plot(pcts, j_ln, '^-', color='#2E86C1', linewidth=2, markersize=7,\n         label='LTN1\u2013NEMF', zorder=3)\n\n# Mark the primary threshold (5%)\nax1.axvline(5, color='gray', linewidth=1, linestyle=':', alpha=0.7)\nax1.text(5.3, ax1.get_ylim()[0] + 0.01, '5% (primary)', fontsize=8,\n         color='gray', rotation=90, va='bottom')\n\nax1.set_xlabel('Network Threshold (%)', fontsize=12)\nax1.set_ylabel('Jaccard Index', fontsize=12)\nax1.set_title('a   Pairwise Jaccard Indices', fontsize=12,\n              fontweight='bold', loc='left')\nax1.legend(fontsize=10)\nax1.grid(True, alpha=0.3)\n\n# Panel B: Partition ratio across thresholds\nax2.plot(pcts, ratios, 'D-', color='#8E44AD', linewidth=2.5, markersize=8)\nax2.axhline(1.0, color='gray', linewidth=1, linestyle='--', alpha=0.5)\nax2.axhline(2.0, color='green', linewidth=1, linestyle='--', alpha=0.5,\n            label='2.0\u00d7 (strong separation)')\nax2.axvline(5, color='gray', linewidth=1, linestyle=':', alpha=0.7)\n\n# Shade strong separation zone\nax2.axhspan(2.0, max(ratios) * 1.15, alpha=0.08, color='green')\n\nax2.set_xlabel('Network Threshold (%)', fontsize=12)\nax2.set_ylabel('Partition Ratio\\n(LTN1\u2013NEMF J / max PELO J)', fontsize=11)\nax2.set_title('b   Two-Module Partition Ratio', fontsize=12,\n              fontweight='bold', loc='left')\nax2.legend(fontsize=9)\nax2.grid(True, alpha=0.3)\n\nplt.suptitle('Threshold Sensitivity Analysis of Two-Module Architecture',\n             fontsize=13, fontweight='bold', y=1.02)\nplt.tight_layout()\nfig_s3.savefig(f'{OUT}/figures/FigureS3_threshold_sensitivity.pdf')\nfig_s3.savefig(f'{OUT}/figures/FigureS3_threshold_sensitivity.png')\nplt.close(fig_s3)\nprint(\"\\n  Figure S3 saved.\")\n\n# Save threshold sensitivity table\nsens_df = pd.DataFrame(sensitivity_rows)\nsens_df.to_csv(f'{OUT}/supplementary/TableS8_threshold_sensitivity.csv', index=False)\nprint(\"  Table S8 saved.\")\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# FINAL SUMMARY\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nprint(f\"\\n{'='*70}\")\nprint(\"SUPPLEMENTARY ANALYSES COMPLETE\")\nprint(\"=\" * 70)\nprint(f\"\\n  OUTPUTS:\")\nprint(f\"    Figures:\")\nprint(f\"      {OUT}/figures/FigureS1_permutation_null.pdf/png\")\nprint(f\"      {OUT}/figures/FigureS2_bootstrap_jaccard.pdf/png\")\nprint(f\"      {OUT}/figures/FigureS3_threshold_sensitivity.pdf/png\")\nprint(f\"    Tables:\")\nprint(f\"      {OUT}/supplementary/TableS5_null_distribution.csv\")\nprint(f\"      {OUT}/supplementary/TableS6_cross_region_all_pairs.csv\")\nprint(f\"      {OUT}/supplementary/TableS7_bootstrap_CIs.csv\")\nprint(f\"      {OUT}/supplementary/TableS8_threshold_sensitivity.csv\")\n\nprint(f\"\\n  KEY RESULTS FOR MANUSCRIPT:\")\nprint(f\"    Permutation null: \u03bc={null_mean:.4f}, \u03c3={null_std:.4f}\")\nfor g1, g2 in pairs:\n    obs_j = pairwise[(g1, g2)][\"jaccard\"]\n    z_score = (obs_j - null_mean) / null_std\n    emp_p = np.sum(null_jaccards >= obs_j) / N_PERM\n    print(f\"    {g1}\u2013{g2}: J={obs_j:.4f}, z={z_score:.1f}, p_emp<{max(emp_p, 1/N_PERM):.4f}\")\n\nprint(f\"\\n    Bootstrap 95% CIs:\")\nfor g1, g2 in pairs:\n    j_lo, j_hi = np.percentile(boot_jaccards[(g1, g2)], [2.5, 97.5])\n    print(f\"    {g1}\u2013{g2}: [{j_lo:.4f}, {j_hi:.4f}]\")\n\nprint(f\"\\n    Threshold sensitivity (partition ratio range):\")\nprint(f\"    {min(ratios):.2f}\u00d7 \u2013 {max(ratios):.2f}\u00d7 across {THRESHOLDS[0]*100:.0f}%\u2013{THRESHOLDS[-1]*100:.0f}% thresholds\")\n\nprint(f\"\\n    Sub-0.80 region pairs: {len(sub80)} total\")\nfor _, row in sub80.iterrows():\n    print(f\"      {row['Gene']}: {row['Region 1']}\u2013{row['Region 2']} \u03c1={row['Spearman \u03c1']:.4f}\")\n\nprint(f\"\\n{'='*70}\")\nprint(\"PASTE ALL OUTPUT ABOVE BACK TO CLAUDE\")\nprint(\"=\" * 70)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}