{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MS1: Two-Module RQC Architecture \u2014 Complete Pipeline\n",
        "\n",
        "Complete reproducible pipeline generating ALL manuscript numbers, Figures 1\u20133, Tables 1\u20133, and Supplementary Tables S1\u2013S4.\n",
        "\n",
        "**Author:** Drake H. Harbert \u2014 Inner Architecture LLC\n",
        "\n",
        "**Environment:** Google Colab, \u226412 GB RAM, Google Drive mounted\n",
        "\n[![Open In Colab](https://colab.research.google.com/github/innerarchitecturellc/rqc-two-module/blob/main/notebooks/MS1_RQC_COMPLETE.ipynb)](https://colab.research.google.com/github/innerarchitecturellc/rqc-two-module/blob/main/notebooks/MS1_RQC_COMPLETE.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 0 \u2014 Install dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# !pip install matplotlib-venn --quiet\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 1 \u2014 Mount drive, load ALL brain regions (RAM-safe)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\ndrive.mount('/content/drive')\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport os, urllib.request, gc, json, time, requests, warnings\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom matplotlib_venn import venn3\nimport seaborn as sns\n\nwarnings.filterwarnings('ignore')\nsns.set_style(\"whitegrid\")\nplt.rcParams.update({'font.size': 10, 'figure.dpi': 300,\n                     'savefig.dpi': 300, 'savefig.bbox': 'tight'})\n\nOUT = '/content/drive/MyDrive/MS1_RQC_Output'\nos.makedirs(OUT, exist_ok=True)\nos.makedirs(f'{OUT}/figures', exist_ok=True)\nos.makedirs(f'{OUT}/tables', exist_ok=True)\nos.makedirs(f'{OUT}/supplementary', exist_ok=True)\n\nGCT_FILE = '/content/drive/MyDrive/GenomicAnalysis/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct.gz'\nPHENO_FILE = '/content/drive/MyDrive/PCDH_SIGMAR1_Analysis/GTEx_Analysis_v8_Annotations_SubjectPhenotypesDS.txt'\n\nSAMPLE_FILE = '/content/GTEx_SampleAttributes.txt'\nif not os.path.exists(SAMPLE_FILE):\n    print(\"Downloading GTEx SampleAttributes...\")\n    url = \"https://storage.googleapis.com/adult-gtex/annotations/v8/metadata-files/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt\"\n    urllib.request.urlretrieve(url, SAMPLE_FILE)\n    print(\"  Done.\")\n\nTARGETS = [\"PELO\", \"LTN1\", \"NEMF\"]\nTOP_PCT = 0.05\n\nREGIONS = {\n    \"BA9\":  \"Brain - Frontal Cortex (BA9)\",\n    \"PUT\":  \"Brain - Putamen (basal ganglia)\",\n    \"HIP\":  \"Brain - Hippocampus\",\n    \"NAC\":  \"Brain - Nucleus accumbens (basal ganglia)\",\n    \"BA24\": \"Brain - Anterior cingulate cortex (BA24)\",\n}\n\n# Identify all brain samples across 5 regions\nsamples_df = pd.read_csv(SAMPLE_FILE, sep=\"\\t\")\n\n# Diagnostic: print actual brain tissue names in dataset\nactual_brain = samples_df[samples_df[\"SMTSD\"].str.contains(\"Brain\", na=False)][\"SMTSD\"].unique()\nprint(\"  GTEx brain tissues found in SampleAttributes:\")\nfor t in sorted(actual_brain):\n    print(f\"    '{t}'\")\n\nregion_samples = {}\nall_brain_ids = []\nfor abbr, full_name in REGIONS.items():\n    ids = samples_df[samples_df[\"SMTSD\"] == full_name][\"SAMPID\"].tolist()\n    region_samples[abbr] = ids\n    all_brain_ids.extend(ids)\n    status = \"OK\" if len(ids) > 0 else \"*** NOT FOUND \u2014 check tissue name ***\"\n    print(f\"  {abbr}: {len(ids)} samples  {status}\")\n\n# Read only brain columns from GCT (single load for all regions)\nheader = pd.read_csv(GCT_FILE, sep='\\t', skiprows=2, nrows=0)\nbrain_cols = [c for c in header.columns if c in all_brain_ids]\nuse_cols = [\"Name\", \"Description\"] + brain_cols\ndel header; gc.collect()\n\nprint(f\"\\nLoading {len(brain_cols)} brain samples from GCT...\")\ngct = pd.read_csv(GCT_FILE, sep='\\t', skiprows=2, usecols=use_cols)\ngene_names = gct[\"Description\"].values\ntpm_all = gct[brain_cols].T.copy()\ntpm_all.columns = gene_names\ndel gct; gc.collect()\n\n# Deduplicate: keep highest median per gene symbol\ntpm_all = tpm_all.T.groupby(level=0).max().T\nprint(f\"  Total: {tpm_all.shape[0]} samples, {tpm_all.shape[1]} genes (pre-filter)\")\n\n# Load phenotype data\npheno = pd.read_csv(PHENO_FILE, sep=\"\\t\")\nsamples_df[\"SUBJID\"] = samples_df[\"SAMPID\"].str.extract(r\"(GTEX-[^-]+)\")[0]\nage_map = {\"20-29\": 25, \"30-39\": 35, \"40-49\": 45,\n           \"50-59\": 55, \"60-69\": 65, \"70-79\": 75}\n\n# Build per-region expression matrices (filtered, log-transformed)\nregion_data = {}\nfor abbr in REGIONS:\n    ids = [s for s in region_samples[abbr] if s in tpm_all.index]\n    tpm_r = tpm_all.loc[ids]\n    medians = tpm_r.median(axis=0)\n    expressed = medians[medians >= 1.0].index\n    tpm_r = tpm_r[expressed]\n    expr_r = np.log2(tpm_r + 1)\n\n    # Merge covariates for primary region\n    meta_r = samples_df[samples_df[\"SAMPID\"].isin(ids)][\n        [\"SAMPID\", \"SUBJID\", \"SMTSISCH\"]\n    ].merge(\n        pheno[[\"SUBJID\", \"AGE\", \"SEX\", \"DTHHRDY\"]], on=\"SUBJID\", how=\"left\"\n    ).set_index(\"SAMPID\").reindex(expr_r.index)\n    meta_r[\"AGE_NUM\"] = meta_r[\"AGE\"].map(age_map)\n\n    region_data[abbr] = {\n        \"expr\": expr_r, \"tpm\": tpm_r, \"meta\": meta_r,\n        \"n_samples\": expr_r.shape[0], \"n_genes\": expr_r.shape[1]\n    }\n    missing = [t for t in TARGETS if t not in expr_r.columns]\n    print(f\"  {abbr}: {expr_r.shape[0]} samples, {expr_r.shape[1]} genes\"\n          + (f\" [MISSING: {missing}]\" if missing else \"\"))\n\ndel tpm_all, pheno; gc.collect()\nprint(\"\\n  All regions loaded.\\n\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 2 \u2014 Primary analysis: genome-wide correlations + overlaps (BA9)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=\" * 70)\nprint(\"PRIMARY ANALYSIS \u2014 BA9\")\nprint(\"=\" * 70)\n\nexpr = region_data[\"BA9\"][\"expr\"]\ntpm  = region_data[\"BA9\"][\"tpm\"]\nmeta = region_data[\"BA9\"][\"meta\"]\nN_SAMPLES = expr.shape[0]\nN_GENES   = expr.shape[1]\n\n# Subset to samples with complete covariates for sensitivity analyses\nvalid = meta.dropna(subset=[\"AGE_NUM\", \"SEX\", \"DTHHRDY\", \"SMTSISCH\"]).index\nexpr_v = expr.loc[valid]\nmeta_v = meta.loc[valid]\n\nfor t in TARGETS:\n    print(f\"  {t}: median TPM = {tpm[t].median():.2f}\")\n\nother_genes = [g for g in expr_v.columns if g not in TARGETS]\nn_other = len(other_genes)\nn_top = int(n_other * TOP_PCT)\nprint(f\"\\n  {N_SAMPLES} samples, {N_GENES} expressed genes\")\nprint(f\"  {len(valid)} samples with complete covariates\")\nprint(f\"  {n_other} non-target genes, top 5% = {n_top}\")\n\n# Genome-wide Pearson correlations\nprint(\"\\nComputing genome-wide correlations...\")\ncorrelations = {}\ntop5_sets = {}\nthresholds = {}\n\nfor target in TARGETS:\n    t_vals = expr_v[target].values\n    corrs = {}\n    for g in other_genes:\n        corrs[g] = stats.pearsonr(t_vals, expr_v[g].values)[0]\n    ranking = pd.Series(corrs).sort_values(ascending=False)\n    correlations[target] = ranking\n    top5_sets[target] = set(ranking.head(n_top).index)\n    thresholds[target] = ranking.iloc[n_top - 1]\n    print(f\"  {target}: top = {ranking.index[0]} (r={ranking.iloc[0]:.4f}), \"\n          f\"threshold r >= {thresholds[target]:.4f}\")\n\n# \u2500\u2500 Pairwise statistics \u2500\u2500\nprint(f\"\\nPAIRWISE NETWORK COMPARISON:\")\npairs = [(\"PELO\", \"LTN1\"), (\"PELO\", \"NEMF\"), (\"LTN1\", \"NEMF\")]\npairwise = {}\n\nfor g1, g2 in pairs:\n    s1, s2 = top5_sets[g1], top5_sets[g2]\n    inter = len(s1 & s2)\n    union = len(s1 | s2)\n    j = inter / union\n    a, b, c = inter, len(s1) - inter, len(s2) - inter\n    d = n_other - len(s1 | s2)\n    oddsratio, fisher_p = stats.fisher_exact([[a, b], [c, d]], alternative='greater')\n    r1, r2 = correlations[g1], correlations[g2]\n    common = r1.index.intersection(r2.index)\n    rho, _ = stats.spearmanr(r1[common], r2[common])\n    pairwise[(g1, g2)] = {\n        \"jaccard\": j, \"shared\": inter, \"union\": union,\n        \"or\": oddsratio, \"fisher_p\": fisher_p, \"spearman\": rho\n    }\n    p_str = f\"{fisher_p:.2e}\" if fisher_p > 0 else \"< 1e-324\"\n    print(f\"  {g1}-{g2}: J={j:.4f}, shared={inter}, \"\n          f\"OR={oddsratio:.2f}, p={p_str}, rho={rho:.4f}\")\n\n# \u2500\u2500 Three-way overlap \u2500\u2500\nP, L, N = top5_sets[\"PELO\"], top5_sets[\"LTN1\"], top5_sets[\"NEMF\"]\nall_three      = P & L & N\npelo_ltn1_only = (P & L) - N\npelo_nemf_only = (P & N) - L\nltn1_nemf_only = (L & N) - P\npelo_only      = P - L - N\nltn1_only      = L - P - N\nnemf_only      = N - P - L\n\ntotal_unique = len(P | L | N)\nvenn_regions = {\n    \"All three (PELO \u2229 LTN1 \u2229 NEMF)\": (len(all_three), all_three),\n    \"LTN1 \u2229 NEMF only\": (len(ltn1_nemf_only), ltn1_nemf_only),\n    \"PELO \u2229 NEMF only\": (len(pelo_nemf_only), pelo_nemf_only),\n    \"PELO \u2229 LTN1 only\": (len(pelo_ltn1_only), pelo_ltn1_only),\n    \"PELO unique\": (len(pelo_only), pelo_only),\n    \"LTN1 unique\": (len(ltn1_only), ltn1_only),\n    \"NEMF unique\": (len(nemf_only), nemf_only),\n}\n\nprint(f\"\\nTHREE-WAY OVERLAP:\")\nfor name, (count, _) in venn_regions.items():\n    pct = count / total_unique * 100\n    print(f\"  {name:35s}: {count:5d}  ({pct:.1f}%)\")\nprint(f\"  {'Total unique':35s}: {total_unique:5d}\")\n\n# Store gene sets for enrichment\ngene_sets_for_enrichment = {\n    \"PELO_full\": list(top5_sets[\"PELO\"]),\n    \"LTN1_full\": list(top5_sets[\"LTN1\"]),\n    \"NEMF_full\": list(top5_sets[\"NEMF\"]),\n    \"PELO_unique\": list(pelo_only),\n    \"LTN1_unique\": list(ltn1_only),\n    \"NEMF_unique\": list(nemf_only),\n    \"shared_all_three\": list(all_three),\n    \"LTN1_NEMF_shared\": list(ltn1_nemf_only),\n}\nbackground_genes = list(expr_v.columns)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 3 \u2014 Agonal stress sensitivity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"AGONAL STRESS SENSITIVITY\")\nprint(\"=\"*70)\n\n# Hardy Scale distribution\nhardy_counts = meta_v[\"DTHHRDY\"].value_counts().sort_index()\nprint(f\"\\n  Hardy Scale distribution (n={len(meta_v)}):\")\nhardy_labels = {0: \"Ventilator\", 1: \"Violent/fast\", 2: \"Fast natural\",\n                3: \"Intermediate\", 4: \"Slow illness\"}\nfor val, cnt in hardy_counts.items():\n    print(f\"    {int(val)} ({hardy_labels.get(int(val), '?')}): n={cnt}\")\nprint(f\"  Ischemic time: median={meta_v['SMTSISCH'].median():.0f} min, \"\n      f\"range={meta_v['SMTSISCH'].min():.0f}-{meta_v['SMTSISCH'].max():.0f}\")\n\ndef partial_corr_vector(target_vals, expr_df, genes, covariates):\n    \"\"\"Compute partial Pearson correlations controlling for covariates.\"\"\"\n    if len(covariates) == 0:\n        return pd.Series({g: stats.pearsonr(target_vals, expr_df[g].values)[0]\n                          for g in genes})\n    Z = np.column_stack(covariates + [np.ones(len(covariates[0]))])\n    t_resid = target_vals - Z @ np.linalg.lstsq(Z, target_vals, rcond=None)[0]\n    corrs = {}\n    for g in genes:\n        g_vals = expr_df[g].values\n        g_resid = g_vals - Z @ np.linalg.lstsq(Z, g_vals, rcond=None)[0]\n        corrs[g] = stats.pearsonr(t_resid, g_resid)[0]\n    return pd.Series(corrs)\n\nmodels = {\n    \"Hardy Scale\": [meta_v[\"DTHHRDY\"].values.astype(float)],\n    \"Ischemic time\": [meta_v[\"SMTSISCH\"].values.astype(float)],\n    \"Hardy + Ischemic\": [meta_v[\"DTHHRDY\"].values.astype(float),\n                         meta_v[\"SMTSISCH\"].values.astype(float)],\n    \"Full model\": [meta_v[\"AGE_NUM\"].values.astype(float),\n                   meta_v[\"SEX\"].values.astype(float),\n                   meta_v[\"DTHHRDY\"].values.astype(float),\n                   meta_v[\"SMTSISCH\"].values.astype(float)],\n}\n\nrp_results = []\nadj_jaccards = {}\n\nfor model_name, covs in models.items():\n    print(f\"\\n  Model: {model_name}\")\n    adj_rankings = {}\n    for target in TARGETS:\n        t_vals = expr_v[target].values\n        ranking = partial_corr_vector(t_vals, expr_v, other_genes, covs)\\\n                  .sort_values(ascending=False)\n        adj_rankings[target] = ranking\n        # Rank preservation\n        unadj_rank = correlations[target].rank(ascending=False)\n        adj_rank = ranking.rank(ascending=False)\n        common = unadj_rank.index.intersection(adj_rank.index)\n        rho, _ = stats.spearmanr(unadj_rank[common], adj_rank[common])\n        rp_results.append({\"gene\": target, \"model\": model_name, \"rho\": rho})\n        print(f\"    {target}: rank preservation rho = {rho:.6f}\")\n\n    # Jaccard under this model\n    top_adj = {t: set(adj_rankings[t].head(n_top).index) for t in TARGETS}\n    for g1, g2 in pairs:\n        inter = len(top_adj[g1] & top_adj[g2])\n        union = len(top_adj[g1] | top_adj[g2])\n        adj_jaccards[(model_name, g1, g2)] = inter / union\n\n# Partition test\nprint(f\"\\n  PARTITION TEST (LTN1-NEMF J / max PELO J):\")\nfor model_name in [\"Unadjusted\"] + list(models.keys()):\n    if model_name == \"Unadjusted\":\n        pl = pairwise[(\"PELO\",\"LTN1\")][\"jaccard\"]\n        pn = pairwise[(\"PELO\",\"NEMF\")][\"jaccard\"]\n        ln = pairwise[(\"LTN1\",\"NEMF\")][\"jaccard\"]\n    else:\n        pl = adj_jaccards.get((model_name, \"PELO\", \"LTN1\"), 0)\n        pn = adj_jaccards.get((model_name, \"PELO\", \"NEMF\"), 0)\n        ln = adj_jaccards.get((model_name, \"LTN1\", \"NEMF\"), 0)\n    ratio = ln / max(pl, pn)\n    print(f\"    {model_name:20s}: {ratio:.2f}x\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 4 \u2014 Multi-region replication\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"MULTI-REGION REPLICATION\")\nprint(\"=\"*70)\n\nregion_correlations = {}\n\nfor abbr in REGIONS:\n    print(f\"\\n  Processing {abbr}...\")\n    rd = region_data[abbr]\n    expr_r = rd[\"expr\"]\n    other_r = [g for g in expr_r.columns if g not in TARGETS]\n    n_top_r = int(len(other_r) * TOP_PCT)\n\n    region_corr = {}\n    for target in TARGETS:\n        if target not in expr_r.columns:\n            print(f\"    {target}: NOT EXPRESSED\")\n            continue\n        t_vals = expr_r[target].values\n        corrs = {}\n        for g in other_r:\n            corrs[g] = stats.pearsonr(t_vals, expr_r[g].values)[0]\n        region_corr[target] = pd.Series(corrs).sort_values(ascending=False)\n    region_correlations[abbr] = region_corr\n\n# Cross-region Spearman rank correlations\n# Use genes expressed in ALL regions as common universe for consistency\nregion_abbrs = list(REGIONS.keys())\nall_region_genes = None\nfor abbr in region_abbrs:\n    rd = region_data[abbr]\n    genes_in_region = set(rd[\"expr\"].columns) - set(TARGETS)\n    if all_region_genes is None:\n        all_region_genes = genes_in_region\n    else:\n        all_region_genes = all_region_genes.intersection(genes_in_region)\nprint(f\"\\n  Common gene universe across all 5 regions: {len(all_region_genes)} genes\")\n\nprint(f\"\\n  Cross-region rank correlations:\")\nregion_abbrs = list(REGIONS.keys())\ncross_region_rho = {t: pd.DataFrame(np.nan, index=region_abbrs,\n                    columns=region_abbrs) for t in TARGETS}\n\nfor target in TARGETS:\n    for i, r1 in enumerate(region_abbrs):\n        for j, r2 in enumerate(region_abbrs):\n            if i >= j:\n                if r1 == r2:\n                    cross_region_rho[target].loc[r1, r2] = 1.0\n                    continue\n                c1 = region_correlations[r1].get(target)\n                c2 = region_correlations[r2].get(target)\n                if c1 is None or c2 is None:\n                    continue\n                # Restrict to common universe across ALL regions\n                common = sorted(all_region_genes.intersection(\n                    c1.index).intersection(c2.index))\n                rho, _ = stats.spearmanr(c1[common], c2[common])\n                cross_region_rho[target].loc[r1, r2] = rho\n                cross_region_rho[target].loc[r2, r1] = rho\n\n    # Summary stats\n    vals = []\n    pair_details = []\n    for i, r1 in enumerate(region_abbrs):\n        for j, r2 in enumerate(region_abbrs):\n            if i < j:\n                v = cross_region_rho[target].loc[r1, r2]\n                if not np.isnan(v):\n                    vals.append(v)\n                    pair_details.append((r1, r2, v))\n    print(f\"  {target}: min={min(vals):.3f}, max={max(vals):.3f}, \"\n          f\"median={np.median(vals):.3f}, all>0.80={all(v>0.80 for v in vals)}\")\n    # Show any pairs below 0.80\n    low_pairs = [(r1, r2, v) for r1, r2, v in pair_details if v < 0.80]\n    if low_pairs:\n        for r1, r2, v in low_pairs:\n            n1 = len(region_correlations[r1].get(target, []))\n            n2 = len(region_correlations[r2].get(target, []))\n            print(f\"    *** LOW: {r1}-{r2} rho={v:.3f} (genes: {r1}={n1}, {r2}={n2})\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 5 \u2014 Cell-type deconvolution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"CELL-TYPE DECONVOLUTION\")\nprint(\"=\"*70)\n\nCELL_MARKERS = {\n    \"Neurons\": [\"SYT1\",\"SNAP25\",\"SLC17A7\",\"GRIN1\",\"GAD1\",\"GAD2\",\n                \"SLC32A1\",\"RBFOX3\",\"STMN2\",\"NRGN\",\"SYP\"],\n    \"Astrocytes\": [\"GFAP\",\"AQP4\",\"SLC1A2\",\"SLC1A3\",\"ALDH1L1\",\n                   \"GJA1\",\"S100B\",\"SOX9\",\"GLUL\"],\n    \"Oligodendrocytes\": [\"MBP\",\"MOG\",\"PLP1\",\"OLIG1\",\"OLIG2\",\n                         \"MAG\",\"CNP\",\"CLDN11\",\"MOBP\"],\n    \"Microglia\": [\"CX3CR1\",\"P2RY12\",\"TMEM119\",\"CSF1R\",\"AIF1\",\n                  \"CD68\",\"ITGAM\",\"TREM2\",\"HEXB\"],\n    \"Endothelial\": [\"CLDN5\",\"FLT1\",\"VWF\",\"PECAM1\",\"CDH5\",\n                    \"TIE1\",\"ERG\",\"ESAM\"],\n    \"OPCs\": [\"PDGFRA\",\"CSPG4\",\"VCAN\",\"GPR17\",\"NEU4\",\n             \"PCDH15\",\"SOX10\"],\n}\n\n# Count total markers available\nall_markers = []\nfor ct, genes in CELL_MARKERS.items():\n    available = [g for g in genes if g in expr_v.columns]\n    all_markers.extend(available)\n    print(f\"  {ct}: {len(available)}/{len(genes)} markers expressed\")\nprint(f\"  Total marker genes used: {len(all_markers)}\")\n\n# Estimate cell-type proportions (mean log2 expression of markers)\nct_props = pd.DataFrame(index=expr_v.index)\nfor ct, genes in CELL_MARKERS.items():\n    available = [g for g in genes if g in expr_v.columns]\n    if available:\n        ct_props[ct] = expr_v[available].mean(axis=1)\n\n# Partial correlations controlling for cell-type proportions\nprint(f\"\\n  Computing cell-type-adjusted correlations...\")\nct_covariates = [ct_props[col].values for col in ct_props.columns]\n\nct_adj_correlations = {}\nfor target in TARGETS:\n    t_vals = expr_v[target].values\n    ranking = partial_corr_vector(t_vals, expr_v, other_genes, ct_covariates)\\\n              .sort_values(ascending=False)\n    ct_adj_correlations[target] = ranking\n    # Rank preservation\n    unadj_rank = correlations[target].rank(ascending=False)\n    adj_rank = ranking.rank(ascending=False)\n    common = unadj_rank.index.intersection(adj_rank.index)\n    rho, _ = stats.spearmanr(unadj_rank[common], adj_rank[common])\n    print(f\"    {target}: rank preservation rho = {rho:.4f}, \"\n          f\"adj threshold = {ranking.iloc[n_top-1]:.4f}\")\n\n# Check LTN1-NEMF convergence after cell-type adjustment\nct_top5 = {t: set(ct_adj_correlations[t].head(n_top).index) for t in TARGETS}\nfor g1, g2 in pairs:\n    inter = len(ct_top5[g1] & ct_top5[g2])\n    union = len(ct_top5[g1] | ct_top5[g2])\n    j = inter / union\n    print(f\"  Cell-type adjusted {g1}-{g2}: J={j:.4f}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 6 \u2014 gProfiler enrichment analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"GENE ONTOLOGY ENRICHMENT (gProfiler)\")\nprint(\"=\"*70)\n\n# Install gprofiler-official (handles API formatting correctly)\nimport subprocess\nsubprocess.call(['pip', 'uninstall', '-y', '-q', 'gProfiler'], \n                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\nsubprocess.check_call(['pip', 'install', '-q', 'gprofiler-official'])\nfrom gprofiler import GProfiler\n\ngp = GProfiler(return_dataframe=True)\n\ndef run_gprofiler(gene_list, background, name=\"query\"):\n    \"\"\"Run gProfiler enrichment using official Python package.\"\"\"\n    try:\n        # Try with custom background first\n        df = gp.profile(\n            organism='hsapiens',\n            query=gene_list,\n            sources=['GO:BP', 'GO:MF', 'GO:CC', 'KEGG', 'REAC'],\n            user_threshold=0.05,\n            significance_threshold_method='g_SCS',\n            background=background,\n            no_evidences=True,\n        )\n        if df is not None and len(df) > 0:\n            # Standardize column names\n            if 'native' in df.columns and 'term_id' not in df.columns:\n                df = df.rename(columns={'native': 'term_id'})\n            if 'name' in df.columns and 'term_name' not in df.columns:\n                df = df.rename(columns={'name': 'term_name'})\n            df['gene_set'] = name\n            print(f\"    OK (custom bg, {len(df)} terms)\")\n            return df\n    except Exception as e:\n        print(f\"    Custom bg failed: {e}\")\n\n    try:\n        # Fallback: annotated background\n        df = gp.profile(\n            organism='hsapiens',\n            query=gene_list,\n            sources=['GO:BP', 'GO:MF', 'GO:CC', 'KEGG', 'REAC'],\n            user_threshold=0.05,\n            significance_threshold_method='g_SCS',\n            no_evidences=True,\n        )\n        if df is not None and len(df) > 0:\n            if 'native' in df.columns and 'term_id' not in df.columns:\n                df = df.rename(columns={'native': 'term_id'})\n            if 'name' in df.columns and 'term_name' not in df.columns:\n                df = df.rename(columns={'name': 'term_name'})\n            df['gene_set'] = name\n            print(f\"    OK (annotated bg, {len(df)} terms)\")\n            return df\n    except Exception as e:\n        print(f\"    Annotated bg failed: {e}\")\n\n    return pd.DataFrame()\n\nall_enrichment = []\nenrichment_sets = {\n    \"PELO_full\": list(top5_sets[\"PELO\"]),\n    \"LTN1_full\": list(top5_sets[\"LTN1\"]),\n    \"NEMF_full\": list(top5_sets[\"NEMF\"]),\n    \"PELO_unique\": list(pelo_only),\n    \"LTN1_unique\": list(ltn1_only),\n    \"NEMF_unique\": list(nemf_only),\n    \"Shared_all_three\": list(all_three),\n    \"LTN1_NEMF_shared\": list(ltn1_nemf_only),\n    \"PELO_LTN1_shared\": list(pelo_ltn1_only),\n    \"PELO_NEMF_shared\": list(pelo_nemf_only),\n}\n\nfor set_name, genes in enrichment_sets.items():\n    if len(genes) < 5:\n        print(f\"  {set_name}: {len(genes)} genes \u2014 skipping (too few)\")\n        continue\n    print(f\"  {set_name}: {len(genes)} genes \u2014 querying gProfiler...\")\n    df = run_gprofiler(genes, background_genes, name=set_name)\n    if len(df) > 0:\n        all_enrichment.append(df)\n        sig = df[df['p_value'] < 0.05]\n        print(f\"    {len(sig)} significant terms\")\n        # Print top 3 per source\n        for src in ['GO:BP', 'GO:MF', 'GO:CC', 'KEGG', 'REAC']:\n            sub = sig[sig['source'] == src].sort_values('p_value').head(3)\n            for _, row in sub.iterrows():\n                print(f\"      {src}: {row['term_name']} (p={row['p_value']:.2e})\")\n    else:\n        print(f\"    No significant terms\")\n    time.sleep(1)  # Rate limiting\n\nif all_enrichment:\n    enrichment_df = pd.concat(all_enrichment, ignore_index=True)\n    enrichment_df.to_csv(f'{OUT}/supplementary/TableS2_enrichment_all.csv', index=False)\n    print(f\"\\n  Saved {len(enrichment_df)} total enrichment terms to TableS2\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 7 \u2014 Custom gene set enrichment (epigenetic regulators + others)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"CUSTOM GENE SET ENRICHMENT\")\nprint(\"=\"*70)\n\nCUSTOM_SETS = {\n    \"Epigenetic regulators\": [\n        \"CHD1\",\"CHD2\",\"CHD3\",\"CHD4\",\"CHD5\",\"CHD6\",\"CHD7\",\"CHD8\",\"CHD9\",\n        \"SMARCA2\",\"SMARCA4\",\"SMARCB1\",\"SMARCC1\",\"SMARCC2\",\"SMARCD1\",\n        \"ARID1A\",\"ARID1B\",\"ARID2\",\n        \"DNMT1\",\"DNMT3A\",\"DNMT3B\",\n        \"TET1\",\"TET2\",\"TET3\",\n        \"KDM1A\",\"KDM2A\",\"KDM2B\",\"KDM3A\",\"KDM4A\",\"KDM5A\",\"KDM5B\",\"KDM6A\",\"KDM6B\",\n        \"KAT2A\",\"KAT2B\",\"KAT5\",\"KAT6A\",\"KAT7\",\"KAT8\",\n        \"HDAC1\",\"HDAC2\",\"HDAC3\",\"HDAC4\",\"HDAC5\",\"HDAC6\",\"HDAC7\",\"HDAC8\",\n        \"HDAC9\",\"HDAC10\",\"HDAC11\",\n        \"EZH1\",\"EZH2\",\"SUZ12\",\"EED\",\n    ],\n    \"Ribosome quality control\": [\n        \"PELO\",\"HBS1L\",\"LTN1\",\"NEMF\",\"ANKZF1\",\"VCP\",\"UFD1\",\"NPLOC4\",\n        \"ZNF598\",\"RACK1\",\"ABCE1\",\"TCF25\",\n    ],\n    \"Proteostasis network\": [\n        \"HSPA1A\",\"HSPA5\",\"HSPA8\",\"HSP90AA1\",\"HSP90AB1\",\"HSP90B1\",\n        \"UBE2D1\",\"UBE2D3\",\"UBE2N\",\"UBE3A\",\"UBB\",\"UBC\",\n        \"PSMA1\",\"PSMA3\",\"PSMB1\",\"PSMB5\",\"PSMC2\",\"PSMD4\",\n        \"ATG5\",\"ATG7\",\"ATG12\",\"BECN1\",\"MAP1LC3B\",\"SQSTM1\",\n    ],\n    \"Vascular markers (negative control)\": [\n        \"PECAM1\",\"CDH5\",\"VWF\",\"FLT1\",\"KDR\",\"ENG\",\"CLDN5\",\"ESAM\",\n        \"ERG\",\"TIE1\",\"TEK\",\"ANGPT1\",\"ANGPT2\",\"NOS3\",\"MCAM\",\n        \"PODXL\",\"EMCN\",\"ROBO4\",\n    ],\n}\n\nn_custom_tests = 0\ncustom_results = []\n\nfor set_name, gene_list in CUSTOM_SETS.items():\n    expressed = [g for g in gene_list if g in expr_v.columns]\n    # Remove targets from consideration if present\n    expressed_clean = [g for g in expressed if g not in TARGETS]\n\n    for target in TARGETS:\n        top_set = top5_sets[target]\n        in_top = [g for g in expressed_clean if g in top_set]\n        k = len(in_top)\n        n_set = len(expressed_clean)\n        if n_set == 0:\n            continue\n        n_custom_tests += 1\n\n        # Fisher's exact test (one-sided)\n        a = k\n        b = len(top_set) - k\n        c = n_set - k\n        d = n_other - len(top_set) - c\n        d = max(d, 0)\n        _, p = stats.fisher_exact([[a, b], [c, d]], alternative='greater')\n        fold = (k / n_set) / (n_top / n_other) if n_set > 0 else 0\n\n        custom_results.append({\n            \"gene_set\": set_name, \"target\": target,\n            \"in_top5\": k, \"total_expressed\": n_set,\n            \"fold_enrichment\": fold, \"p_value\": p,\n            \"genes_in_top5\": \", \".join(sorted(in_top)) if in_top else \"\",\n        })\n\n        if p < 0.05:\n            print(f\"  ** {target} x {set_name}: \"\n                  f\"{k}/{n_set} in top 5%, {fold:.1f}-fold, p={p:.2e}\")\n            if in_top:\n                print(f\"     Genes: {', '.join(sorted(in_top))}\")\n\ncustom_df = pd.DataFrame(custom_results)\n\n# Bonferroni correction for all custom tests\ncustom_df[\"p_bonferroni\"] = np.minimum(custom_df[\"p_value\"] * n_custom_tests, 1.0)\nprint(f\"\\n  Total custom tests: {n_custom_tests}\")\nprint(f\"  Bonferroni-significant results:\")\nsig_custom = custom_df[custom_df[\"p_bonferroni\"] < 0.05]\nfor _, row in sig_custom.iterrows():\n    print(f\"    {row['target']} x {row['gene_set']}: p_raw={row['p_value']:.2e}, \"\n          f\"p_bonf={row['p_bonferroni']:.2e}\")\n\n# Multi-region custom enrichment for NEMF epigenetic regulators\nprint(f\"\\n  Multi-region epigenetic enrichment for NEMF:\")\nepi_genes_all = CUSTOM_SETS[\"Epigenetic regulators\"]\n\nfor abbr in REGIONS:\n    rc = region_correlations[abbr].get(\"NEMF\")\n    if rc is None:\n        continue\n    other_r = [g for g in region_data[abbr][\"expr\"].columns if g not in TARGETS]\n    n_top_r = int(len(other_r) * TOP_PCT)\n    top_r = set(rc.head(n_top_r).index)\n    expressed_r = [g for g in epi_genes_all if g in other_r]\n    in_top_r = [g for g in expressed_r if g in top_r]\n    k_r, n_r = len(in_top_r), len(expressed_r)\n    if n_r > 0:\n        _, p_r = stats.fisher_exact(\n            [[k_r, len(top_r)-k_r],\n             [n_r-k_r, max(len(other_r)-len(top_r)-(n_r-k_r), 0)]],\n            alternative='greater')\n        fold_r = (k_r/n_r) / (n_top_r/len(other_r))\n        sig_str = \"**SIG**\" if p_r < 0.05 else \"\"\n        print(f\"    {abbr}: {k_r}/{n_r}, {fold_r:.1f}-fold, p={p_r:.4f} {sig_str}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 8 \u2014 FIGURE 1: Two-module architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"GENERATING FIGURES\")\nprint(\"=\"*70)\n\nfig1, axes = plt.subplots(1, 3, figsize=(16, 5.5))\n\n# \u2500\u2500 Fig 1a: Pathway schematic \u2500\u2500\nax = axes[0]\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.set_aspect('equal')\nax.axis('off')\nax.set_title('a', fontsize=14, fontweight='bold', loc='left')\n\n# Module A (PELO)\nrect_a = mpatches.FancyBboxPatch((0.5, 6.5), 3.5, 2.5, boxstyle=\"round,pad=0.2\",\n                                  facecolor='#4ECDC4', alpha=0.3, edgecolor='#2C7A75', lw=2)\nax.add_patch(rect_a)\nax.text(2.25, 8.5, 'Module A', fontsize=10, fontweight='bold', ha='center', color='#2C7A75')\nax.text(2.25, 7.7, 'Surveillance\u2013\\nmRNA Decay', fontsize=8, ha='center', color='#2C7A75')\n# PELO box\npelo_box = mpatches.FancyBboxPatch((1.2, 6.8), 2.1, 0.7, boxstyle=\"round,pad=0.1\",\n                                    facecolor='#4ECDC4', edgecolor='#2C7A75', lw=1.5)\nax.add_patch(pelo_box)\nax.text(2.25, 7.15, 'PELO', fontsize=10, fontweight='bold', ha='center', va='center')\n\n# Module B (LTN1-NEMF)\nrect_b = mpatches.FancyBboxPatch((5.5, 6.5), 4.0, 2.5, boxstyle=\"round,pad=0.2\",\n                                  facecolor='#FF6B6B', alpha=0.3, edgecolor='#C0392B', lw=2)\nax.add_patch(rect_b)\nax.text(7.5, 8.5, 'Module B', fontsize=10, fontweight='bold', ha='center', color='#C0392B')\nax.text(7.5, 7.7, 'Nascent Chain\\nProcessing', fontsize=8, ha='center', color='#C0392B')\n# LTN1 box\nltn1_box = mpatches.FancyBboxPatch((5.8, 6.8), 1.5, 0.7, boxstyle=\"round,pad=0.1\",\n                                    facecolor='#FF6B6B', edgecolor='#C0392B', lw=1.5)\nax.add_patch(ltn1_box)\nax.text(6.55, 7.15, 'LTN1', fontsize=10, fontweight='bold', ha='center', va='center')\n# NEMF box\nnemf_box = mpatches.FancyBboxPatch((7.8, 6.8), 1.5, 0.7, boxstyle=\"round,pad=0.1\",\n                                    facecolor='#FF6B6B', edgecolor='#C0392B', lw=1.5)\nax.add_patch(nemf_box)\nax.text(8.55, 7.15, 'NEMF', fontsize=10, fontweight='bold', ha='center', va='center')\n\n# Arrow: PELO \u2192 LTN1-NEMF\nax.annotate('', xy=(5.5, 7.5), xytext=(4.0, 7.5),\n            arrowprops=dict(arrowstyle='->', lw=2, color='gray'))\nax.text(4.75, 7.8, 'Ribosome\\nsplitting', fontsize=7, ha='center', color='gray')\n\n# Labels below\nax.text(2.25, 5.8, 'J = 0.165\\n(PELO\u2013LTN1)', fontsize=7, ha='center', color='gray')\nax.text(7.5, 5.8, 'J = 0.461\\n(LTN1\u2013NEMF)', fontsize=7, ha='center', color='#C0392B',\n        fontweight='bold')\n\n# Stalled ribosome at top\nax.text(5.0, 9.5, '80S Stalled Ribosome', fontsize=9, ha='center',\n        fontweight='bold', style='italic', color='#555')\n\n# \u2500\u2500 Fig 1b: Three-way Venn \u2500\u2500\nax = axes[1]\nax.set_title('b', fontsize=14, fontweight='bold', loc='left')\nv = venn3(subsets=(len(pelo_only), len(ltn1_only), len(pelo_ltn1_only),\n                   len(nemf_only), len(pelo_nemf_only), len(ltn1_nemf_only),\n                   len(all_three)),\n          set_labels=('PELO', 'LTN1', 'NEMF'),\n          set_colors=('#4ECDC4', '#FF6B6B', '#FFB347'), alpha=0.6, ax=ax)\n# Bold the LTN1-NEMF shared count\nif v.get_label_by_id('110'):\n    v.get_label_by_id('110').set_fontweight('bold')\n    v.get_label_by_id('110').set_fontsize(11)\n\n# \u2500\u2500 Fig 1c: Jaccard heatmap \u2500\u2500\nax = axes[2]\nax.set_title('c', fontsize=14, fontweight='bold', loc='left')\nj_matrix = pd.DataFrame(\n    [[1.0, pairwise[(\"PELO\",\"LTN1\")][\"jaccard\"], pairwise[(\"PELO\",\"NEMF\")][\"jaccard\"]],\n     [pairwise[(\"PELO\",\"LTN1\")][\"jaccard\"], 1.0, pairwise[(\"LTN1\",\"NEMF\")][\"jaccard\"]],\n     [pairwise[(\"PELO\",\"NEMF\")][\"jaccard\"], pairwise[(\"LTN1\",\"NEMF\")][\"jaccard\"], 1.0]],\n    index=TARGETS, columns=TARGETS\n)\nsns.heatmap(j_matrix, annot=True, fmt='.3f', cmap='YlOrRd',\n            vmin=0, vmax=0.5, square=True, linewidths=1,\n            cbar_kws={'label': 'Jaccard Index', 'shrink': 0.8}, ax=ax)\nax.set_title('c', fontsize=14, fontweight='bold', loc='left')\n# Add baseline annotation\nax.text(1.5, 3.3, 'Random baseline: J \u2248 0.02\u20130.05', fontsize=7,\n        ha='center', style='italic', color='gray')\n\nplt.tight_layout()\nfig1.savefig(f'{OUT}/figures/Figure1_two_module_architecture.pdf')\nfig1.savefig(f'{OUT}/figures/Figure1_two_module_architecture.png')\nplt.close(fig1)\nprint(\"  Figure 1 saved.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 9 \u2014 FIGURE 2: GO enrichment of unique gene sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if all_enrichment:\n    fig2, axes2 = plt.subplots(2, 2, figsize=(14, 10))\n\n    panels = [\n        (\"PELO_unique\", \"PELO unique (528 genes)\", axes2[0, 0], '#4ECDC4'),\n        (\"LTN1_unique\", \"LTN1 unique (235 genes)\", axes2[0, 1], '#FF6B6B'),\n        (\"NEMF_unique\", \"NEMF unique (246 genes)\", axes2[1, 0], '#FFB347'),\n        (\"Shared_all_three\", \"Shared RQC core (166 genes)\", axes2[1, 1], '#9B59B6'),\n    ]\n\n    panel_labels = ['a', 'b', 'c', 'd']\n\n    for idx, (set_name, title, ax, color) in enumerate(panels):\n        ax.set_title(panel_labels[idx], fontsize=14, fontweight='bold', loc='left')\n\n        subset = enrichment_df[enrichment_df['gene_set'] == set_name].copy()\n        if len(subset) == 0:\n            ax.text(0.5, 0.5, 'No enrichment data', transform=ax.transAxes,\n                    ha='center', va='center')\n            continue\n\n        # Top 5 GO:BP terms by p-value\n        bp = subset[subset['source'] == 'GO:BP'].sort_values('p_value').head(5)\n        if len(bp) == 0:\n            bp = subset.sort_values('p_value').head(5)\n\n        bp = bp.sort_values('p_value', ascending=True)\n        y_pos = range(len(bp))\n        bars = ax.barh(y_pos, -np.log10(bp['p_value'].values), color=color, alpha=0.8)\n        ax.set_yticks(list(y_pos))\n        # Truncate long names\n        labels = [n[:45] + '...' if len(n) > 45 else n for n in bp['term_name'].values]\n        ax.set_yticklabels(labels, fontsize=8)\n        ax.set_xlabel('-log\u2081\u2080(p-value)', fontsize=9)\n        ax.set_title(f'{panel_labels[idx]}   {title}', fontsize=10,\n                     fontweight='bold', loc='left')\n\n    plt.tight_layout()\n    fig2.savefig(f'{OUT}/figures/Figure2_GO_enrichment.pdf')\n    fig2.savefig(f'{OUT}/figures/Figure2_GO_enrichment.png')\n    plt.close(fig2)\n    print(\"  Figure 2 saved.\")\nelse:\n    print(\"  Figure 2 SKIPPED \u2014 no enrichment data (gProfiler may have been unreachable)\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 10 \u2014 FIGURE 3: Multi-region replication heatmaps\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig3, axes3 = plt.subplots(1, 3, figsize=(16, 4.5))\n\nregion_labels = list(REGIONS.keys())\n\nfor idx, target in enumerate(TARGETS):\n    ax = axes3[idx]\n    mat = cross_region_rho[target].astype(float)\n    mask = np.triu(np.ones_like(mat, dtype=bool), k=1)  # mask upper triangle\n    sns.heatmap(mat, annot=True, fmt='.3f', cmap='YlGnBu',\n                vmin=0.75, vmax=1.0, square=True, linewidths=1,\n                mask=mask, cbar_kws={'shrink': 0.7}, ax=ax)\n    ax.set_title(f'{\"abc\"[idx]}   {target}', fontsize=12, fontweight='bold', loc='left')\n\nplt.tight_layout()\nfig3.savefig(f'{OUT}/figures/Figure3_multi_region_replication.pdf')\nfig3.savefig(f'{OUT}/figures/Figure3_multi_region_replication.png')\nplt.close(fig3)\nprint(\"  Figure 3 saved.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 11 \u2014 Tables (manuscript body)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"GENERATING TABLES\")\nprint(\"=\"*70)\n\n# Table 1: Pairwise comparison\ntable1_rows = []\nfor g1, g2 in pairs:\n    d = pairwise[(g1, g2)]\n    p_str = f\"{d['fisher_p']:.2e}\" if d['fisher_p'] > 0 else \"< 10\u207b\u00b3\u00b2\u2074\"\n    table1_rows.append({\n        \"Gene A\": g1, \"Gene B\": g2,\n        \"Jaccard\": f\"{d['jaccard']:.3f}\",\n        \"Shared genes\": d['shared'],\n        \"Fisher OR\": f\"{d['or']:.2f}\",\n        \"Fisher p\": p_str,\n        \"Rank \u03c1\": f\"{d['spearman']:.3f}\",\n    })\ntable1 = pd.DataFrame(table1_rows)\ntable1.to_csv(f'{OUT}/tables/Table1_pairwise_comparison.csv', index=False)\nprint(\"  Table 1 saved.\")\n\n# Table 2: Three-way overlap\ntable2_rows = []\nfor name, (count, _) in venn_regions.items():\n    table2_rows.append({\n        \"Category\": name,\n        \"Gene count\": count,\n        \"% of total\": f\"{count/total_unique*100:.1f}\",\n    })\ntable2 = pd.DataFrame(table2_rows)\ntable2.to_csv(f'{OUT}/tables/Table2_three_way_overlap.csv', index=False)\nprint(\"  Table 2 saved.\")\n\n# Table 3: Cross-region ranges\ntable3_rows = []\nfor target in TARGETS:\n    vals = []\n    for i, r1 in enumerate(region_labels):\n        for j, r2 in enumerate(region_labels):\n            if i < j:\n                v = cross_region_rho[target].loc[r1, r2]\n                if not np.isnan(v):\n                    vals.append(v)\n    table3_rows.append({\n        \"Gene\": target,\n        \"Min \u03c1\": f\"{min(vals):.2f}\",\n        \"Max \u03c1\": f\"{max(vals):.2f}\",\n        \"Median \u03c1\": f\"{np.median(vals):.2f}\",\n        \"All > 0.80\": \"Yes\" if all(v > 0.80 for v in vals) else \"No\",\n    })\ntable3 = pd.DataFrame(table3_rows)\ntable3.to_csv(f'{OUT}/tables/Table3_cross_region_ranges.csv', index=False)\nprint(\"  Table 3 saved.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 12 \u2014 Supplementary tables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"GENERATING SUPPLEMENTARY MATERIALS\")\nprint(\"=\"*70)\n\n# Table S1: Complete genome-wide co-expression rankings\ns1_rows = []\nfor g in other_genes:\n    row = {\"Gene\": g}\n    for target in TARGETS:\n        row[f\"{target}_r\"] = correlations[target].get(g, np.nan)\n        row[f\"{target}_rank\"] = correlations[target].rank(ascending=False).get(g, np.nan)\n    # p-values for each correlation\n    for target in TARGETS:\n        r_val = correlations[target].get(g, np.nan)\n        if not np.isnan(r_val):\n            n = len(expr_v)\n            t_stat = r_val * np.sqrt((n - 2) / (1 - r_val**2))\n            p_val = 2 * stats.t.sf(abs(t_stat), df=n-2)\n            row[f\"{target}_p\"] = p_val\n        else:\n            row[f\"{target}_p\"] = np.nan\n    s1_rows.append(row)\n\ntable_s1 = pd.DataFrame(s1_rows)\n# Sort by PELO rank\ntable_s1 = table_s1.sort_values(\"PELO_rank\")\ntable_s1.to_csv(f'{OUT}/supplementary/TableS1_genome_wide_rankings.csv', index=False)\nprint(f\"  Table S1: {len(table_s1)} genes saved.\")\n\n# Table S2: Already saved above (gProfiler enrichment)\n# (saved in Cell 6)\n\n# Table S3: Custom gene set enrichment + sensitivity analyses\ncustom_df.to_csv(f'{OUT}/supplementary/TableS3_custom_enrichment.csv', index=False)\n\n# Add sensitivity summary to S3\nsensitivity_rows = []\nfor r in rp_results:\n    sensitivity_rows.append(r)\nsensitivity_df = pd.DataFrame(sensitivity_rows)\nsensitivity_df.to_csv(f'{OUT}/supplementary/TableS3_sensitivity_rank_preservation.csv',\n                       index=False)\n\n# Agonal Jaccard table\nagonal_rows = []\nfor model_name in [\"Unadjusted\"] + list(models.keys()):\n    row = {\"Model\": model_name}\n    for g1, g2 in pairs:\n        key = f\"{g1}-{g2}\"\n        if model_name == \"Unadjusted\":\n            row[key] = pairwise[(g1, g2)][\"jaccard\"]\n        else:\n            row[key] = adj_jaccards.get((model_name, g1, g2), np.nan)\n    agonal_rows.append(row)\nagonal_df = pd.DataFrame(agonal_rows)\nagonal_df.to_csv(f'{OUT}/supplementary/TableS3_agonal_jaccard.csv', index=False)\nprint(\"  Table S3 (custom enrichment + sensitivity) saved.\")\n\n# Table S4: Complete list of 166 shared genes\ns4_rows = []\nfor g in sorted(all_three):\n    row = {\"Gene\": g}\n    for target in TARGETS:\n        row[f\"{target}_r\"] = correlations[target].get(g, np.nan)\n    row[\"Mean_r\"] = np.mean([correlations[t].get(g, np.nan) for t in TARGETS])\n    s4_rows.append(row)\ntable_s4 = pd.DataFrame(s4_rows).sort_values(\"Mean_r\", ascending=False)\ntable_s4.to_csv(f'{OUT}/supplementary/TableS4_shared_166_genes.csv', index=False)\nprint(f\"  Table S4: {len(table_s4)} shared genes saved.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 13 \u2014 Random baseline validation (empirical J for random pairs)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n{'='*70}\")\nprint(\"RANDOM BASELINE VALIDATION\")\nprint(\"=\"*70)\n\nnp.random.seed(42)\nn_random = 1000\ngene_pool = [g for g in expr_v.columns if g not in TARGETS]\n\n# Precompute z-scored expression matrix for fast correlation via dot product\nexpr_mat = expr_v[gene_pool].values  # (n_samples, n_genes)\n# Z-score each gene (column): (x - mean) / std\nexpr_z = (expr_mat - expr_mat.mean(axis=0)) / (expr_mat.std(axis=0, ddof=1) + 1e-12)\nn_samp = expr_z.shape[0]\nprint(f\"  Expression matrix: {expr_z.shape[0]} samples \u00d7 {expr_z.shape[1]} genes (z-scored)\")\n\nrandom_jaccards = []\ntop_n = int(len(gene_pool) * 0.05)\n\nfor i in range(n_random):\n    g1_idx = np.random.randint(0, len(gene_pool))\n    g2_idx = np.random.randint(0, len(gene_pool))\n    while g2_idx == g1_idx:\n        g2_idx = np.random.randint(0, len(gene_pool))\n\n    # Vectorized correlation: dot product of z-scored vectors / (n-1)\n    r1 = expr_z[:, g1_idx] @ expr_z / (n_samp - 1)  # shape: (n_genes,)\n    r2 = expr_z[:, g2_idx] @ expr_z / (n_samp - 1)\n\n    # Zero out self-correlations\n    r1[g1_idx] = -999\n    r1[g2_idx] = -999\n    r2[g1_idx] = -999\n    r2[g2_idx] = -999\n\n    # Top 5% by correlation\n    t1 = set(np.argsort(r1)[-top_n:])\n    t2 = set(np.argsort(r2)[-top_n:])\n\n    inter = len(t1 & t2)\n    union = len(t1 | t2)\n    j = inter / union if union > 0 else 0\n    random_jaccards.append(j)\n\n    if (i + 1) % 200 == 0:\n        print(f\"  {i+1}/{n_random} random pairs computed...\")\n\nrj = np.array(random_jaccards)\nprint(f\"\\n  Random baseline Jaccard (n={n_random}):\")\nprint(f\"    Mean = {rj.mean():.4f}\")\nprint(f\"    Median = {np.median(rj):.4f}\")\nprint(f\"    SD = {rj.std():.4f}\")\nprint(f\"    Range = {rj.min():.4f} \u2013 {rj.max():.4f}\")\nprint(f\"    2.5th\u201397.5th percentile = {np.percentile(rj,2.5):.4f} \u2013 {np.percentile(rj,97.5):.4f}\")\n\n# Z-scores for observed Jaccards\nfor (g1, g2), d in pairwise.items():\n    z = (d['jaccard'] - rj.mean()) / rj.std()\n    print(f\"    {g1}-{g2}: J={d['jaccard']:.4f}, z={z:.1f} SD above random mean\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CELL 14 \u2014 Final summary output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"\u2550\u2550\u2550 COMPLETE MANUSCRIPT NUMBER VERIFICATION \u2550\u2550\u2550\")\nprint(\"=\" * 70)\n\nprint(f\"\\nDATASET:\")\nprint(f\"  Primary region: BA9, n = {N_SAMPLES} samples\")\nprint(f\"  Expressed genes: {N_GENES}\")\nprint(f\"  Non-target genes: {n_other}\")\nprint(f\"  Top 5% = {n_top} genes per target\")\n\nprint(f\"\\nMEDIAN EXPRESSION:\")\nfor t in TARGETS:\n    print(f\"  {t}: {region_data['BA9']['tpm'][t].median():.2f} TPM\")\n\nprint(f\"\\nTHRESHOLDS:\")\nfor t in TARGETS:\n    print(f\"  {t}: r >= {thresholds[t]:.3f}\")\n\nprint(f\"\\n--- TABLE 1 ---\")\nfor (g1, g2), d in pairwise.items():\n    p_str = f\"{d['fisher_p']:.2e}\" if d['fisher_p'] > 0 else \"< 10^-324\"\n    print(f\"  {g1}-{g2}: J={d['jaccard']:.3f}, shared={d['shared']}, \"\n          f\"OR={d['or']:.2f}, p={p_str}, rho={d['spearman']:.3f}\")\n\nprint(f\"\\n--- TABLE 2 ---\")\nfor name, (count, _) in venn_regions.items():\n    print(f\"  {name}: {count} ({count/total_unique*100:.1f}%)\")\nprint(f\"  Total: {total_unique}\")\n\nprint(f\"\\n--- TABLE 3 (cross-region ranges) ---\")\nfor target in TARGETS:\n    vals = []\n    for i, r1 in enumerate(region_labels):\n        for j, r2 in enumerate(region_labels):\n            if i < j:\n                v = cross_region_rho[target].loc[r1, r2]\n                if not np.isnan(v):\n                    vals.append(v)\n    print(f\"  {target}: {min(vals):.2f}\u2013{max(vals):.2f}, \"\n          f\"median={np.median(vals):.2f}\")\n\nprint(f\"\\n--- AGONAL SENSITIVITY ---\")\nprint(f\"  Rank preservation (full model):\")\nfor r in rp_results:\n    if r['model'] == 'Full model':\n        print(f\"    {r['gene']}: rho = {r['rho']:.4f}\")\n\nprint(f\"\\n  Partition ratios:\")\nfor model_name in [\"Unadjusted\"] + list(models.keys()):\n    if model_name == \"Unadjusted\":\n        pl = pairwise[(\"PELO\",\"LTN1\")][\"jaccard\"]\n        pn = pairwise[(\"PELO\",\"NEMF\")][\"jaccard\"]\n        ln = pairwise[(\"LTN1\",\"NEMF\")][\"jaccard\"]\n    else:\n        pl = adj_jaccards.get((model_name, \"PELO\", \"LTN1\"), 0)\n        pn = adj_jaccards.get((model_name, \"PELO\", \"NEMF\"), 0)\n        ln = adj_jaccards.get((model_name, \"LTN1\", \"NEMF\"), 0)\n    ratio = ln / max(pl, pn)\n    print(f\"    {model_name}: {ratio:.2f}x\")\n\nprint(f\"\\n--- RANDOM BASELINE ---\")\nprint(f\"  J = {rj.mean():.3f} \u00b1 {rj.std():.3f} (n={n_random})\")\n\nprint(f\"\\n--- OUTPUT FILES ---\")\nprint(f\"  Figures:  {OUT}/figures/\")\nprint(f\"  Tables:   {OUT}/tables/\")\nprint(f\"  Suppl:    {OUT}/supplementary/\")\n\nprint(f\"\\n{'='*70}\")\nprint(\"PIPELINE COMPLETE\")\nprint(\"=\"*70)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}